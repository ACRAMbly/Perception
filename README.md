# ACRAMbly-Perception

**Real-time 6DoF Object Pose Estimation for Robotic Assembly**

[![ROS2](https://img.shields.io/badge/ROS2-Jazzy-blue.svg)](https://docs.ros.org/en/jazzy/)
[![Python](https://img.shields.io/badge/Python-3.9+-green.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ“– Overview

**ACRAMbly-Perception** is a robust perception pipeline developed for the ACRAMbly Master Project at the University of Bremen. This system enables autonomous robots to accurately detect and estimate 6DoF (6 Degrees of Freedom) poses of objects in real-time assembly scenarios.

The pipeline integrates:
- **FoundationPose**: State-of-the-art 6D pose estimation and tracking
- **Grounded SAM**: Text-prompted object detection and segmentation  
- **ROS2 Jazzy**: Native integration for seamless robotic system communication
- **Intel RealSense**: RGB-D camera support for depth-aware perception

### ğŸ¯ Project Context

This work is part of the **ACRAMbly Master Project** (12 ECTS, SoSe 2025 & WiSe 2025/2026) at the University of Bremen, supervised by Prof. Michael Beetz. The project aims to build a cognitive architecture for autonomous robotic assembly using PyCRAM, combining industrial automation with AI-driven robot control.

**Key Project Goals:**
- Integrate an assembly station into a cognitive architecture
- Plan action sequences for complete assembly tasks
- Precisely estimate 6D poses of assembly components
- Control dual UR10 robot arms with high precision

---

## âœ¨ Features

- âœ… **Real-time 6DoF Pose Estimation**: Track objects with millimeter precision
- âœ… **Text-Prompted Detection**: Natural language object detection ("red cube", "metal gear", etc.)
- âœ… **Multi-Object Support**: Concurrent tracking of multiple objects with thread-safe operations
- âœ… **ROS2 Native**: Full ROS2 Jazzy integration with message passing and TF transforms
- âœ… **RealSense Ready**: Out-of-the-box support for Intel RealSense D400 series
- âœ… **Mesh-Based Tracking**: Support for custom CAD models (OBJ, PLY formats)
- âœ… **Visualization Tools**: Real-time 3D bounding boxes, coordinate axes, and pose overlays
- âœ… **Debug Modes**: Comprehensive logging and image saving for development

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  RealSense Camera                       â”‚
â”‚              (RGB-D Image Acquisition)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ROS2 Jazzy Topics                          â”‚
â”‚  /camera/color/image_raw                                â”‚
â”‚  /camera/depth/image_rect_raw                           â”‚
â”‚  /camera/color/camera_info                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FoundationPose ROS2 Node                        â”‚
â”‚         (integration_test.py)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  1. Grounded SAM Detection                      â”‚   â”‚
â”‚  â”‚     - Text prompt processing                    â”‚   â”‚
â”‚  â”‚     - Bounding box detection                    â”‚   â”‚
â”‚  â”‚     - Mask segmentation                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                   â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  2. FoundationPose Estimation                   â”‚   â”‚
â”‚  â”‚     - Initial pose estimation                   â”‚   â”‚
â”‚  â”‚     - Pose refinement                           â”‚   â”‚
â”‚  â”‚     - Pose tracking across frames               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Output Topics                              â”‚
â”‚  /foundationpose/object_pose (PoseStamped)              â”‚
â”‚  /foundationpose/visualization (Image)                  â”‚
â”‚  /tf (TransformStamped)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- Ubuntu 24.04 (or compatible)
- ROS2 Jazzy
- CUDA-capable GPU (recommended: RTX 3090 or better)
- Intel RealSense Camera (D435, D455, or similar)
- Python 3.9+

### Installation

**See [INSTALLATION.md](INSTALLATION.md) for detailed setup instructions.**

Quick setup:
```bash
# Clone the repository
git clone https://github.com/ACRAMbly/ACRAMbly-Perception.git
cd ACRAMbly-Perception

# Install dependencies
pip install -r requirements.txt

# Build extensions (required for first-time setup)
bash build_all.sh

# Download model weights (see INSTALLATION.md for links)
```

### Running the Perception Pipeline

1. **Start the RealSense camera**:
```bash
source /opt/ros/jazzy/setup.bash
ros2 launch realsense2_camera rs_launch.py align_depth.enable:=true
```

2. **Launch the perception node**:
```bash
source /opt/ros/jazzy/setup.bash
cd /path/to/ACRAMbly-Perception

python3 integration_test.py \
  --mesh_path demo_data/cube/mesh/textured.obj \
  --prompt_text "cube" \
  --debug 1
```

3. **View results**:
- RViz2: `ros2 run rviz2 rviz2`
- Console logs and visualization window

---

## ğŸ“ Project Structure

```
ACRAMbly-Perception/
â”œâ”€â”€ integration_test.py           # Main ROS2 perception node
â”œâ”€â”€ estimater.py                   # FoundationPose estimator wrapper
â”œâ”€â”€ datareader.py                  # Data loading utilities
â”œâ”€â”€ Utils.py                       # Visualization and helper functions
â”‚
â”œâ”€â”€ GroundedSAM_demo/             # Grounded SAM integration
â”‚   â”œâ”€â”€ grounded_sam.py           # Main GroundedSAM class
â”‚   â”œâ”€â”€ ros2_realsense_groundedsam.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ ros2_integration/              # ROS2 bridge components
â”‚   â”œâ”€â”€ ros2_bridge.py            # Alternative bridge implementation
â”‚   â”œâ”€â”€ foundationpose_node.py    # Node wrapper
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ rosbag_testing/               # ROS bag testing utilities
â”‚   â”œâ”€â”€ fixed_demo.py             # Offline testing with bags
â”‚   â””â”€â”€ COMPLETE_WORKFLOW_DOCUMENTATION.md
â”‚
â”œâ”€â”€ demo_data/                    # Sample data and test meshes
â”‚   â”œâ”€â”€ cube/
â”‚   â”œâ”€â”€ mustard0/
â”‚   â””â”€â”€ YCB_Video/
â”‚
â”œâ”€â”€ weights/                      # Model checkpoints (download separately)
â”œâ”€â”€ checkpoints/                  # GroundingDINO checkpoints
â”‚
â”œâ”€â”€ learning/                     # Training scripts (original FoundationPose)
â”œâ”€â”€ bundlesdf/                    # BundleSDF integration
â””â”€â”€ mycpp/                        # C++ extensions
```

---

## ğŸ® Usage Examples

### Example 1: Single Object Tracking

```bash
python3 integration_test.py \
  --mesh_path demo_data/mustard0/mesh/textured.obj \
  --prompt_text "mustard bottle" \
  --debug 2 \
  --publish_pose \
  --publish_tf
```

### Example 2: Multi-Object Detection

```bash
python3 multi_thread_multi_object.py \
  --mesh_dir demo_data/ycbv/models/ \
  --prompt_text "objects on table" \
  --debug 1
```

### Example 3: With Custom Camera Topics

```bash
python3 integration_test.py \
  --rgb_topic /my_camera/rgb \
  --depth_topic /my_camera/depth \
  --camera_info_topic /my_camera/info \
  --mesh_path path/to/mesh.obj \
  --prompt_text "target object"
```

---

## ğŸ“Š Performance

Tested on: NVIDIA RTX 3090, Intel i9-12900K, 64GB RAM

| Metric | Performance |
|--------|-------------|
| Detection FPS | ~10-15 Hz |
| Pose Estimation FPS | ~8-12 Hz |
| Pose Accuracy (YCB-Video) | <2cm translation error |
| Latency (camera to pose) | ~100-150ms |

---

## ğŸ”§ Configuration

Key parameters in `integration_test.py`:

```python
--prompt_text          # Natural language object description
--mesh_path           # Path to object CAD model (OBJ/PLY)
--mesh_obj_id         # Object ID for YCB/BOP datasets
--debug               # Debug level (0: none, 1: basic, 2: full)
--box_threshold       # GroundingDINO detection threshold (default: 0.25)
--text_threshold      # Text prompt confidence threshold (default: 0.25)
--sam_vit_model       # SAM variant (sam_b, sam_l, sam_h)
--publish_pose        # Publish PoseStamped messages
--publish_tf          # Broadcast TF transforms
```

---

## ğŸ› Troubleshooting

### Camera not detected
```bash
# Check RealSense device
rs-enumerate-devices

# Verify ROS2 topics
ros2 topic list | grep camera
```

### CUDA out of memory
- Reduce image resolution
- Use smaller SAM model (`sam_b` instead of `sam_l`)
- Close other GPU applications

### No detections
- Adjust `--box_threshold` and `--text_threshold`
- Improve prompt text (be more specific)
- Check lighting conditions and object visibility

---

## ğŸ“š Documentation

- [Installation Guide](INSTALLATION.md)
- [ROS2 Integration Details](ros2_integration/README.md)
- [Complete Workflow](rosbag_testing/COMPLETE_WORKFLOW_DOCUMENTATION.md)
- [FoundationPose Paper](https://arxiv.org/abs/2312.08344)
- [Grounded SAM](https://github.com/IDEA-Research/Grounded-Segment-Anything)

---

## ğŸ¤ Contributing

This is an academic project developed as part of the ACRAMbly Master Project. Contributions, suggestions, and improvements are welcome!

### Development Team

**Author**: [Ahtasham Ilyas]  
**Institution**: University of Bremen  
**Supervisors**: Prof. Michael Beetz, Jonas Dech, Tom Schierenbeck, Malte Huerkamp

---

## ğŸ“„ License

This project builds upon:
- **FoundationPose** - NVIDIA Corporation ([Paper](https://arxiv.org/abs/2312.08344))
- **Grounded SAM** - IDEA Research ([GitHub](https://github.com/IDEA-Research/Grounded-Segment-Anything))

Please respect the original licenses of these components.

---

## ğŸ“ Citation

If you use this work in your research, please cite:

```bibtex
@mastersthesis{acramblyperc2025,
  author = {Ahtasham Ilyas},
  title = {Real-time 6DoF Pose Estimation for Robotic Assembly: ACRAMbly Perception Pipeline},
  school = {University of Bremen},
  year = {2025},
  type = {Master's Project}
}
```

Also cite the original FoundationPose work:
```bibtex
@InProceedings{foundationposewen2024,
  author    = {Bowen Wen and Wei Yang and Jan Kautz and Stan Birchfield},
  title     = {{FoundationPose}: Unified 6D Pose Estimation and Tracking of Novel Objects},
  booktitle = {CVPR},
  year      = {2024},
}
```

---

## ğŸ”— Related Projects

- [PyCRAM](https://github.com/cram2/pycram) - Cognitive Robot Abstract Machine
- [FoundationPose](https://github.com/NVlabs/FoundationPose) - Original implementation
- [Isaac ROS Pose Estimation](https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_pose_estimation) - Production ROS version

---

## ğŸ“§ Contact

For questions or collaboration:
- **GitHub Issues**: [Open an issue](https://github.com/ACRAMbly/ACRAMbly-Perception/issues)
- **Project Website**: [ACRAMbly Project Page](https://ai.uni-bremen.de/teaching/)

---

**Made with â¤ï¸ at the Institute for Artificial Intelligence, University of Bremen**
